datasets:
  input:
    path: /Users/shreyashankar/.docetl/files/reviews.json
    source: local
    type: file
default_model: gpt-4o-mini
operations:
- model: gpt-4o-mini
  name: unnest_weaknesses
  recursive: true
  type: unnest
  unnest_key: weaknesses
- blocking_keys:
  - weakness_shortname
  blocking_threshold: 0.5263
  comparison_prompt: 'you are comparing two types of weaknesses described in AI paper
    reviews. please determine if these two weakness types should be grouped together
    because they are essentially the same:


    weakness 1: {{ input1.weakness_shortname }}

    quotes to support weakness 1: {{ input1.quotes }}

    weakness 2: {{ input2.weakness_shortname }}

    quotes to support weakness 2: {{ input2.quotes }}


    if the quotes mention the same idea, these two weaknesses should be merged together.'
  embedding_model: text-embedding-3-small
  model: gpt-4o-mini
  name: canonicalize_weaknesses
  output:
    schema:
      weakness_shortname: string
  resolution_prompt: 'you are comparing two types of weaknesses described in AI paper
    reviews. determine a canonical name for the weakness type for the following weakness
    types:


    {% for input in inputs %}

    Weakness: {{ input.weakness_shortname }}

    {% endfor %}


    the canonicalized weakness should be 4-5 words at most.'
  type: resolve
- model: gpt-4o-mini
  name: summarize_weakness
  output:
    schema:
      summary: string
  prompt: 'you are analyzing weaknesses stated in AI paper reviews. for the weakness
    {{ reduce_key }}, here are many of the quotes from reviews that correspond to
    it:


    {% for input in inputs %}

    Quotes: {{ input.quotes }}

    {% endfor %}


    Based on these quotes, summarize why the submissions exhibited this weakness.
    Include quotes in your summary.'
  reduce_key:
  - weakness_shortname
  type: reduce
- method: token_count
  method_kwargs:
    num_tokens: 10974
  name: split_extract_weaknesses
  split_key: content
  type: split
- name: parallel_map_content_extract_weaknesses
  output:
    schema:
      content_summary: string
      headers: 'list[{header: string, level: integer}]'
  prompts:
  - model: gpt-4o-mini
    name: header_extraction_content_extract_weaknesses
    output_keys:
    - headers
    prompt: "Analyze the following chunk of a document and extract any headers you\
      \ see.\n\n        { input.content_chunk }\n\n        Examples of headers and\
      \ their levels based on the document structure:\n        - \"Summary\" (level\
      \ 1)\n- \"Strengths\" (level 2)\n- \"Weaknesses\" (level 2)\n- \"Questions\"\
      \ (level 2)\n\n        Overall structure: The document comprises multiple paper\
      \ reviews, with each review beginning with a 'Summary' section. Following the\
      \ summary, sections titled 'Strengths', 'Weaknesses', and 'Questions' break\
      \ down the review into further details. Each of these sections discusses specific\
      \ parts of the review process, suggesting a structured review format typical\
      \ in academic peer-review contexts.\n\n        Provide your analysis as a list\
      \ of dictionaries, where each dictionary contains a 'header' (string) and 'level'\
      \ (integer). For example:\n\n        [\n            {\"header\": \"Summary\"\
      , \"level\": 1},\n            {\"header\": \"Strengths\", \"level\": 2}\n  \
      \      ]\n\n        Only include headers you find in the text, do not add any\
      \ that are not present. Use the patterns described for each level to identify\
      \ headers:\n        Level 1: The word 'Summary' appears at the beginning of\
      \ each section detailing the summary of the reviewed paper.\nLevel 2: These\
      \ sections are named with capitalized titles and are typically bullet points\
      \ or listed after the 'Summary' section, discussing different aspects of the\
      \ paper review.\n        "
  - model: gpt-4o-mini
    name: summary_content_extract_weaknesses
    output_keys:
    - content_summary
    prompt: 'Summarize the following chunk: {{ input.content_chunk }}


      Focus on summarizing weaknesses that are recurrent across multiple submissions
      such as insufficient argumentation, lack of empirical evaluations, or methodological
      gaps.'
  type: parallel_map
- content_key: content_chunk
  doc_header_key: headers
  doc_id_key: split_extract_weaknesses_id
  name: gather_content_extract_weaknesses
  order_key: split_extract_weaknesses_chunk_num
  peripheral_chunks:
    next:
      head:
        count: 2
    previous:
      middle:
        content_key: content_summary
      tail:
        count: 2
  type: gather
- model: gpt-4o-mini
  name: submap_extract_weaknesses
  output:
    schema:
      weaknesses: 'list[{weakness_shortname: string, quotes: string}]'
  prompt: 'Extract common weaknesses from this review:


    {{ input.content_chunk_rendered }}


    Focus on weaknesses that might apply to multiple submissions, not just this one.
    Only process the main chunk.'
  type: map
- associative: true
  input:
    schema:
      weaknesses: 'list[{weakness_shortname: string, quotes: string}]'
  model: gpt-4o-mini
  name: subreduce_extract_weaknesses
  output:
    schema:
      weaknesses: 'list[{weakness_shortname: string, quotes: string}]'
  pass_through: true
  prompt: "{\n  \"weaknesses\": [\n    {% for input in inputs %}\n      {% for weakness\
    \ in input['weaknesses'] %}\n        {\n          \"weakness_shortname\": \"{{\
    \ weakness['weakness_shortname'] }}\",\n          \"quotes\": \"{{ weakness['quotes']\
    \ }}\"\n        },\n      {% endfor %}\n    {% endfor %}\n  ]\n}"
  reduce_key:
  - split_extract_weaknesses_id
  synthesize_resolve: false
  type: reduce
pipeline:
  output:
    intermediate_dir: /Users/shreyashankar/Documents/hacking/docetl-examples/iclr-2024-reviews/intermediate
    path: /Users/shreyashankar/Documents/hacking/docetl-examples/iclr-2024-reviews/output.json
    type: file
  steps:
  - input: input
    name: data_processing
    operations:
    - split_extract_weaknesses
    - parallel_map_content_extract_weaknesses
    - gather_content_extract_weaknesses
    - submap_extract_weaknesses
    - subreduce_extract_weaknesses
    - unnest_weaknesses
    - canonicalize_weaknesses
    - summarize_weakness
